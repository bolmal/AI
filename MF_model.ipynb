{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T14:18:34.706701Z",
     "start_time": "2025-02-01T14:18:34.454868Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('interpark_reviews.csv')\n",
    "print(df.columns)"
   ],
   "id": "8cd5d22ffa766e9f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['url', 'title', 'review', 'view', 'likes', 'stars', 'blank', 'userid',\n",
      "       'date', 'star_rating'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T14:41:24.771016Z",
     "start_time": "2025-02-01T14:41:24.748614Z"
    }
   },
   "cell_type": "code",
   "source": [
    "r_cols = ['title','userid','star_rating']\n",
    "DF = df[r_cols].copy(deep=True)\n",
    "\n",
    "# \"NONAME\"이 포함된 행 제거\n",
    "DF = DF[DF[\"title\"] != \"NO NAME\"]"
   ],
   "id": "c7c538ebefaf93c2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 title      userid  star_rating\n",
      "0         2024 Someday Christmas in 여수  tmddu***..          5.0\n",
      "1                2024 성시경 연말 콘서트 〈성시경〉  blonc***..          5.0\n",
      "2      2024 영탁 단독 콘서트 “TAK SHOW3” - 부산  sunny***..          5.0\n",
      "3                       벤슨 분 첫 단독 내한공연      zx5***          5.0\n",
      "4  2024-25 이무진 전국투어 콘서트 ［별책부록］ - 서울 앵콜     orol***          5.0\n",
      "(43919, 3)\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T14:56:37.494150Z",
     "start_time": "2025-02-01T14:56:37.468249Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 중복 제거\n",
    "DF = DF.drop_duplicates()\n",
    "print(DF.shape)"
   ],
   "id": "d63a1f0647e49050",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36181, 3)\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T14:56:45.047094Z",
     "start_time": "2025-02-01T14:56:45.029589Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# user encoding\n",
    "user_dict = {}\n",
    "for user in set(DF[\"userid\"]):\n",
    "    user_dict[user] = len(user_dict)\n",
    "n_users = len(user_dict)\n",
    "print(n_users)"
   ],
   "id": "94ffec00df45db47",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22257\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T15:23:32.195125Z",
     "start_time": "2025-02-01T15:23:28.382925Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Item encoding\n",
    "from sklearn.utils import shuffle\n",
    "item_dict = {}\n",
    "start_point = n_users\n",
    "for item in set(DF[\"title\"]):\n",
    "    item_dict[item] = start_point + len(item_dict)\n",
    "n_items = len(item_dict)\n",
    "start_point += n_items\n",
    "num_x = start_point\n",
    "DF = shuffle(DF,random_state=1)"
   ],
   "id": "9a8d8b385025ed9c",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T15:36:47.833739Z",
     "start_time": "2025-02-01T15:36:46.756987Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# generate X data\n",
    "import numpy as np\n",
    "data = [] # 변수 x의 값을 [인덱스,값]의 형태로 저장\n",
    "y = [] # 평점 데이터\n",
    "w0 = np.mean(DF['star_rating']) # 전체 편향값\n",
    "\n",
    "for i in range(len(DF)):\n",
    "    case = DF.iloc[i]\n",
    "    x_index = []\n",
    "    x_value = []\n",
    "    x_index.append(user_dict[case[\"userid\"]]) # user encoding\n",
    "    x_value.append(1)\n",
    "    x_index.append(item_dict[case[\"title\"]])\n",
    "    x_value.append(1)\n",
    "    data.append([x_index, x_value])\n",
    "    y.append(case[\"star_rating\"]-w0)\n",
    "    if (i%5000)==0:\n",
    "        print('Encoding',i,'cases...')"
   ],
   "id": "e437059ec520fef0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding 0 cases...\n",
      "Encoding 5000 cases...\n",
      "Encoding 10000 cases...\n",
      "Encoding 15000 cases...\n",
      "Encoding 20000 cases...\n",
      "Encoding 25000 cases...\n",
      "Encoding 30000 cases...\n",
      "Encoding 35000 cases...\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T17:06:11.402903Z",
     "start_time": "2025-02-01T17:01:13.174497Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def RMSE(y_true,y_pred):\n",
    "    return np.sqrt(np.mean((np.array(y_true) - np.array(y_pred))**2))\n",
    "\n",
    "# FM 구현\n",
    "class FM() :\n",
    "    def __init__(self,N,K,data,y,alpha,beta,train_ratio = 0.75,\n",
    "                 iterations=100,tolerance=0.005,l2_reg=True,verbose=True):\n",
    "        self.K=K # latent feature의 수\n",
    "        self.N=N # 변수 x의 수\n",
    "        self.n_case = len(data)\n",
    "        self.alpha = alpha # 학습률\n",
    "        self.beta = beta # 정규화 계수\n",
    "        self.iterations = iterations # 반복횟수\n",
    "        self.tolerance = tolerance # 반복을 중단하는 RMSE의 기준인 tolerance\n",
    "        self.l2_reg = l2_reg # 정규화를 할지 여부를 나타내는 값\n",
    "        self.verbose = verbose # 학습 상황을 표시할지 나타내는 값\n",
    "        \n",
    "        # 변수의 편향을 나타내는 w벡터 초기화\n",
    "        self.w = np.random.normal(scale=1./self.N,size = (self.N))\n",
    "        # 잠재요인 행렬 v 초기화\n",
    "        self.v = np.random.normal(scale=1./self.K,size = (self.N,self.K))\n",
    "        \n",
    "        # Train/Test 분리\n",
    "        cutoff = int(train_ratio*len(data))\n",
    "        self.train_x = data[:cutoff]\n",
    "        self.train_y = y[:cutoff]\n",
    "        self.test_x = data[cutoff:]\n",
    "        self.test_y = y[cutoff:]\n",
    "        \n",
    "    # Training 하면서 RMSE 계산\n",
    "    def test(self):\n",
    "        # SGD를 iterations 숫자만큼 진행\n",
    "        best_RMSE = 10000\n",
    "        best_iteration = 0\n",
    "        training_process = []\n",
    "        for i in range(self.iterations):\n",
    "            # SGD & Train RMSE 계산\n",
    "            rmse1 = self.sgd(self.train_x,self.train_y)\n",
    "            # Test RMSE 계산\n",
    "            rmse2 = self.test_rmse(self.test_x,self.test_y)\n",
    "            training_process.append([i,rmse1,rmse2])\n",
    "            \n",
    "            if self.verbose:\n",
    "                if(i+1)%10==0:\n",
    "                    print(\"Iteration: %d ; Train RMSE = %.6f ; Test RMSE = %.6f\" % (i+1,rmse1,rmse2))\n",
    "            \n",
    "            if best_RMSE > rmse2:\n",
    "                best_RMSE = rmse2\n",
    "                best_iteration = i\n",
    "            # RMSE가 정해진 tolerance보다 더 악화되었으면 학습을 중단\n",
    "            elif(rmse2-best_RMSE) > self.tolerance: break\n",
    "        \n",
    "        print(best_iteration,best_RMSE)\n",
    "        return training_process\n",
    "    \n",
    "            \n",
    "    # w,v 업데이트를 위한 Stochastic gradient descent\n",
    "    def sgd(self,x_data,y_data):\n",
    "        y_pred = []\n",
    "        for data,y in zip(x_data,y_data):\n",
    "            x_idx = data[0] # x의 인덱스\n",
    "            x_0 = np.array(data[1]) # 해당 x의 값\n",
    "            x_1 = x_0.reshape(-1,1) # x의 값을 2차원으로 변형 (2차원인 v행렬과 연산을 위해서)\n",
    "            \n",
    "            # 편향값 계산\n",
    "            bias_score = np.sum(self.w[x_idx]*x_0)\n",
    "            \n",
    "            # score 계산\n",
    "            vx = self.v[x_idx] * (x_1) # v matrix * x\n",
    "            sum_vx = np.sum(vx,axis = 0) # sigma(vx)\n",
    "            sum_vx_2 = np.sum(vx*vx,axis = 0) # (v matrix * x)의 제곱\n",
    "            latent_score = 0.5 * np.sum(np.square(sum_vx) - sum_vx_2) # FM 변형식\n",
    "            \n",
    "            # 예측값 계산\n",
    "            y_hat = bias_score + latent_score\n",
    "            y_pred.append(y_hat)\n",
    "            error = y - y_hat\n",
    "            \n",
    "            # w,v 업데이트\n",
    "            if self.l2_reg: # 정규화하는 경우의 업데이트\n",
    "                self.w[x_idx] += error * self.alpha * (x_0 - self.beta * self.w[x_idx])\n",
    "                self.v[x_idx] += error * self.alpha * ((x_1) * sum(vx) - (vx*x_1) - self.beta * self.v[x_idx])\n",
    "            else: # 정규화하지 않는 경우 (update rule)\n",
    "                self.w[x_idx] += error * self.alpha * x_0\n",
    "                self.v[x_idx] += error * self.alpha * ((x_1) * sum(vx) - (vx*x_1))\n",
    "        return RMSE(y_data,y_pred)\n",
    "    \n",
    "    def test_rmse(self,x_data,y_data):\n",
    "        y_pred = []\n",
    "        for data,y in zip(x_data,y_data):\n",
    "            y_hat = self.predict(data[0],data[1])\n",
    "            y_pred.append(y_hat)\n",
    "        return RMSE(y_data,y_pred)\n",
    "        \n",
    "    # 데이터 중 하나의 행에 대한 예측값을 계산하는 함수\n",
    "    # 위의 sgd() 함수에서 계산하는것과 동일\n",
    "    def predict(self,idx,x):\n",
    "        x_0 = np.array(x)\n",
    "        x_1 = x_0.reshape(-1,1)\n",
    "        \n",
    "        # 편향값 계산\n",
    "        bias_score = np.sum(self.w[idx]*x_0)\n",
    "        \n",
    "        # score 계산\n",
    "        vx = self.v[idx] * (x_1)\n",
    "        sum_vx = np.sum(vx,axis = 0)\n",
    "        sum_vx_2 = np.sum(vx*vx,axis = 0)\n",
    "        latent_score = 0.5 * np.sum(np.square(sum_vx) - sum_vx_2)\n",
    "        \n",
    "        # 예측값 계산\n",
    "        y_hat = bias_score + latent_score\n",
    "        return y_hat\n",
    "\n",
    "K = 350\n",
    "fm1 = FM(num_x,K,data,y,alpha=0.0014,beta=0.075,train_ratio=0.75,iterations=200,tolerance=0.005,l2_reg=True,verbose=True)\n",
    "result = fm1.test()\n",
    "        "
   ],
   "id": "5e2c67a5b51e1c03",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10 ; Train RMSE = 0.563515 ; Test RMSE = 0.594920\n",
      "Iteration: 20 ; Train RMSE = 0.540284 ; Test RMSE = 0.581873\n",
      "Iteration: 30 ; Train RMSE = 0.526311 ; Test RMSE = 0.576901\n",
      "Iteration: 40 ; Train RMSE = 0.515714 ; Test RMSE = 0.574688\n",
      "Iteration: 50 ; Train RMSE = 0.506733 ; Test RMSE = 0.573660\n",
      "Iteration: 60 ; Train RMSE = 0.498690 ; Test RMSE = 0.573228\n",
      "Iteration: 70 ; Train RMSE = 0.491267 ; Test RMSE = 0.573133\n",
      "Iteration: 80 ; Train RMSE = 0.484287 ; Test RMSE = 0.573243\n",
      "Iteration: 90 ; Train RMSE = 0.477634 ; Test RMSE = 0.573483\n",
      "Iteration: 100 ; Train RMSE = 0.471218 ; Test RMSE = 0.573811\n",
      "Iteration: 110 ; Train RMSE = 0.464960 ; Test RMSE = 0.574198\n",
      "Iteration: 120 ; Train RMSE = 0.458781 ; Test RMSE = 0.574624\n",
      "Iteration: 130 ; Train RMSE = 0.452594 ; Test RMSE = 0.575076\n",
      "Iteration: 140 ; Train RMSE = 0.446300 ; Test RMSE = 0.575545\n",
      "Iteration: 150 ; Train RMSE = 0.439794 ; Test RMSE = 0.576022\n",
      "Iteration: 160 ; Train RMSE = 0.432972 ; Test RMSE = 0.576500\n",
      "Iteration: 170 ; Train RMSE = 0.425757 ; Test RMSE = 0.576977\n",
      "Iteration: 180 ; Train RMSE = 0.418128 ; Test RMSE = 0.577450\n",
      "Iteration: 190 ; Train RMSE = 0.410139 ; Test RMSE = 0.577921\n",
      "68 0.5731316013005995\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "510db903f3dd2a7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
